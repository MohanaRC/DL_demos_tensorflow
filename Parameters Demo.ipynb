{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f81be7",
   "metadata": {},
   "source": [
    "# DEMO for dimensions and parameters calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0495182",
   "metadata": {},
   "source": [
    "Let's build a simple CNN, visualize the model and figure out how the dimesions and parameters are calculated. It's great if you've used Tensorflow Functional API before, else there will be sufficient details to follow this notebook easily. \n",
    "\n",
    "For this demo we'll build a very simple classifier with 2 sets of convolution, batch normalization and maxpooling layers followed by a single dense layer. We'll train the model for 5 epochs on MNSIT dataset. We won't concern ourselves with the training results as such. \n",
    "\n",
    "To run this notebook, I am using the following package versions:\n",
    "\n",
    "Tensorflow: 2.8.0\n",
    "\n",
    "Tensorflow datasets: 4.6.0\n",
    "\n",
    "There might be minor variations in the code for different versions of these packages.\n",
    "\n",
    "Note: Tensorboard isn't an essential for this demo but just adding it cause it looks cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b3a02",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11aaa10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd305e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6514fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(inputs):\n",
    "    '''\n",
    "       Defining a basic CNN model for classification with 2 conv2d, 2 batch norm, 2 max pooling and one dense layer.\n",
    "       Parameters\n",
    "       inputs: input images\n",
    "       Output:\n",
    "       output_layer: output from final dense layer. Number of classes = 10\n",
    "    '''\n",
    "    \n",
    "    ### First set of conv2d and batchnorm\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
    "    bn1 =  tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    \n",
    "    ### First maxpool\n",
    "    max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(bn1)\n",
    "    \n",
    "    ### Second set of conv2d and batchnorm\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)\n",
    "    bn2 =  tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    \n",
    "    ### Second max pool\n",
    "    max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n",
    "    \n",
    "    ### Flatten it for the dense layer\n",
    "    flatten_layer = tf.keras.layers.Flatten()(max_pool_2)\n",
    "    \n",
    "    ### Two dense layers and output\n",
    "    first_dense = tf.keras.layers.Dense(128, activation='relu')(flatten_layer)\n",
    "    output_layer = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(first_dense)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363241ce",
   "metadata": {},
   "source": [
    "In functional API the inputs and outputs hae to be put together using tf.keras.Models. This makes is flexible to handle multiple inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f905bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    '''Put the model together\n",
    "       Output\n",
    "       model: The entire cnn model'''\n",
    "    #Define the inputs\n",
    "    inputs = tf.keras.layers.Input(shape=(28, 28, 1,))\n",
    "    #Get the encoder output\n",
    "    cnn_op= basic_cnn(inputs)\n",
    "    #Store the outputs of the bottleneck layer for visualisation and analysis\n",
    "    #Put it together and get your model\n",
    "    model = tf.keras.Model(inputs =inputs, outputs=cnn_op)\n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4bb731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 878,986\n",
      "Trainable params: 878,858\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Lets call the model now\n",
    "basic_cnn_model = cnn_model()\n",
    "basic_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959b3d5",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Pretty straightforward here with MNIST. Just normalize and we are set to go. Just fetch the train dataset and run a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b96721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.1039 - accuracy: 0.9682\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0403 - accuracy: 0.9876\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0214 - accuracy: 0.9930\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0165 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 37540), started 0:05:48 ago. (Use '!kill 37540' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d032a531b88e35b1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d032a531b88e35b1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(features):\n",
    "    # Normalize the images and return (image, label) pairs\n",
    "    return tf.cast(features['image'], tf.float32) / 255., features['label']\n",
    "\n",
    "dataset = tfds.load('mnist', split=tfds.Split.TRAIN, data_dir='./data')\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "## Compile the model with optimizer, loss and metrics. Note: Custom functions can be used here as well\n",
    "basic_cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## Initialize callbacks to work for Tensorboard (not the main objective here, just showcasing)\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# train the model for 5 epoch(just this once for the purpose of demo!)\n",
    "history=basic_cnn_model.fit(dataset, epochs=5, callbacks=[tensorboard_callback])\n",
    "%tensorboard --logdir logs  --host localhost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aebb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
