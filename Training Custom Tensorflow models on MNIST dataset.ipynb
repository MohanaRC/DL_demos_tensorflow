{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e81c9b",
   "metadata": {},
   "source": [
    "# Training Custom Tensorflow models on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f0604",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process of training a custom CNN model on MNIST dataset using Tensorflow. \n",
    "\n",
    "To run this notebook, I am using the following package versions:\n",
    "\n",
    "Tensorflow: 2.8.0\n",
    "\n",
    "Tensorflow datasets: 4.6.0\n",
    "\n",
    "There might be minor variations in the code for different versions of these packages.\n",
    "\n",
    "This notebook has been created as supplentary material for the Series: Everything you need to know about CNNs: Quick Introduction to Model Training (Link: )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5a5ce",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2099bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "#from resnets_utils import *Keras\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666cbdd",
   "metadata": {},
   "source": [
    "## Inputs and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725e625",
   "metadata": {},
   "source": [
    "Here we load the MNIST dataset using Tensorflow datasets and split it into train, validation and test datasets.\n",
    "\n",
    "We'll also assign the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "451f7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size to be used in this notebook\n",
    "BATCH_SIZE=128\n",
    "\n",
    "splits = [\"train[:70%]\", \"train[70%:85%]\", \"train[85%:]\"]\n",
    "\n",
    "# load the dataset given the splits defined above\n",
    "splits, info = tfds.load(\"mnist\", with_info=True, as_supervised=True, split=splits)\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits[\"train\"].num_examples\n",
    "num_classes = info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1d9b3",
   "metadata": {},
   "source": [
    "Let's view some of the details of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a970d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "238d11a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='~\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cdf4dd",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We'll need to do a little bit processing before we can use the data. These include,\n",
    "\n",
    "* Type casting\n",
    "\n",
    "* Normalizing the pixel values\n",
    "\n",
    "* Reshaping it to icnlude the batch size (the extra 1, for RGB images there would be 4 channels in total to accomodate for the RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b308a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image and normalize the pixel values\n",
    "def format_image(image, label):\n",
    "    \"\"\"\n",
    "       Function to resize the image and normalise the pixel_values\n",
    "    \"\"\"\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.reshape(image, shape=(28, 28, 1,))    \n",
    "    return image, label\n",
    "\n",
    "# Prepare training, test and validation batches\n",
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_batches = test_examples.map(format_image).batch(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b995d",
   "metadata": {},
   "source": [
    "Note: This is a simple example to demonstrate building models and training using Tensorflow's functional API and we are ignoring approaches to improve model performance like data augmentation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c80e9ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b793f",
   "metadata": {},
   "source": [
    "## Stack up the layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4bb59",
   "metadata": {},
   "source": [
    "Let's stack up the layers in the following order:\n",
    "\n",
    "* Add a padding to the input\n",
    "\n",
    "* Stage 1: Two back to back 2D convolutions with relu activation, with 3x3 filters and stride set to 1, followed by a single maxopooling with window size of 3x3 and stride of 2\n",
    "\n",
    "* Stage 1: Two back to back 2D convolutions with relu activation, with 3x3 filters and stride set to 1, followed by a single maxopooling with window size of 3x3 and stride of 2\n",
    "\n",
    "* Stage 3: Flattening followed a dense layer with ReLU activation and another dense layer with ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf72f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customCNN(input_shape = (28, 28, 1), classes = 10):\n",
    "    \"\"\"\n",
    "    Implementation of VGG16 architecture:\n",
    "  \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Tensorflow\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    # Stage 3 \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='relu', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c710fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 34, 34, 1)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        640       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 279,608\n",
      "Trainable params: 279,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model and set the number of classes\n",
    "model = customCNN(input_shape = (28, 28, 1), classes = 10)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64ffd0",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331937d3",
   "metadata": {},
   "source": [
    "Add your loss function, optimizer, metrics. Compile the model and your're ready to train your custom tensorflow model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c330c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "329/329 [==============================] - 112s 336ms/step - loss: 0.6536 - accuracy: 0.7756 - val_loss: 0.1512 - val_accuracy: 0.9590\n",
      "Epoch 2/3\n",
      "329/329 [==============================] - 113s 343ms/step - loss: 0.0911 - accuracy: 0.9734 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 3/3\n",
      "329/329 [==============================] - 120s 364ms/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 0.0616 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a6a3df880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.RMSprop(0.001)  ,\n",
    "                metrics=[\"accuracy\"])\n",
    "EPOCHS = 3\n",
    "model.fit(train_batches,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=validation_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d348773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab6853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
